{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying dog breedsusing SageMaker\n",
    "\n",
    "This notebook lists all the steps that you need to complete the complete this project. You will need to complete all the TODOs in this notebook as well as in the README and the two python scripts included with the starter code.\n",
    "\n",
    "\n",
    "The dataset contains images from 133 dog breeds divided into training, testing and validation datasets.\n",
    "\n",
    "We will use the ResNet50 model to perform transfer learning on a dataset using pretrained models available in Pytorch.\n",
    "\n",
    "Once the model is trained (using hyperparameter tuning), you will need to deploy the model to a Sagemaker Endpoint. To test your deployment, you also need to query the deployed model with a sample image and get a prediction.\n",
    "\n",
    "**Pipeline**\n",
    "\n",
    "To finish this project, you will have to perform tasks and use tools that a typical ML Engineer does as a part of their job. Broadly, your project has 3 main steps:\n",
    "\n",
    "1. Data Preparations\n",
    "2. Training\n",
    "3. Depoy\n",
    "\n",
    "As an ML Engineer, you will need to track and coordinate the flow of data (which could be images, models, metrics etc) through these different steps. The goal of this project is not to train an accurate model, but to set up an infrastructure that enables other developers to train such models.\n",
    "\n",
    "\n",
    "**Note:** This notebook has a bunch of code and markdown cells with TODOs that you have to complete. These are meant to be helpful guidelines for you to finish your project while meeting the requirements in the project rubrics. Feel free to change the order of these the TODO's and use more than one TODO code cell to do all your tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting smdebug\n",
      "  Downloading smdebug-1.0.12-py2.py3-none-any.whl (270 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.1/270.1 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from smdebug) (1.21.6)\n",
      "Collecting pyinstrument==3.4.2\n",
      "  Downloading pyinstrument-3.4.2-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.3/83.3 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from smdebug) (20.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /opt/conda/lib/python3.7/site-packages (from smdebug) (3.20.1)\n",
      "Requirement already satisfied: boto3>=1.10.32 in /opt/conda/lib/python3.7/site-packages (from smdebug) (1.24.62)\n",
      "Collecting pyinstrument-cext>=0.2.2\n",
      "  Downloading pyinstrument_cext-0.2.4-cp37-cp37m-manylinux2010_x86_64.whl (20 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.10.32->smdebug) (1.0.1)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.62 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.10.32->smdebug) (1.27.62)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from boto3>=1.10.32->smdebug) (0.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->smdebug) (2.4.6)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from packaging->smdebug) (1.14.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.7/site-packages (from botocore<1.28.0,>=1.27.62->boto3>=1.10.32->smdebug) (1.26.12)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.7/site-packages (from botocore<1.28.0,>=1.27.62->boto3>=1.10.32->smdebug) (2.8.1)\n",
      "Installing collected packages: pyinstrument-cext, pyinstrument, smdebug\n",
      "Successfully installed pyinstrument-3.4.2 pyinstrument-cext-0.2.4 smdebug-1.0.12\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# TODO: Install any packages that you might need\n",
    "# For instance, you will need the smdebug package\n",
    "!pip install smdebug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import any packages that you might need\n",
    "# For instance you will need Boto3 and Sagemaker\n",
    "import sagemaker\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "TODO: Explain what dataset you are using for this project. Maybe even give a small overview of the classes, class distributions etc that can help anyone not familiar with the dataset get a better understand of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Fetch and upload the data to AWS S3\n",
    "\n",
    "# Command to download and unzip data\n",
    "!wget https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/dogImages.zip\n",
    "!unzip dogImages.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize**\n",
    "\n",
    "See [Visualize DogBreeds](Visualize_DogBreeds.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data to S3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the sagemaker SDK grab the current region, execution role and bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Bucket: sagemaker-us-east-1-011919444977\n",
      "AWS Region: us-east-1\n",
      "RoleArn: arn:aws:iam::011919444977:role/service-role/AmazonSageMaker-ExecutionRole-20221103T102549\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "bucket= session.default_bucket()\n",
    "print(\"Default Bucket: {}\".format(bucket))\n",
    "\n",
    "region = session.boto_region_name\n",
    "print(\"AWS Region: {}\".format(region))\n",
    "\n",
    "role = get_execution_role() #sagemaker iam role\n",
    "print(\"RoleArn: {}\".format(role))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this data we can easily sync your data up to S3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport os\\n\\nos.environ[\"DEFAULT_S3_BUCKET\"] = bucket\\n!aws s3 sync ./dogImages/train s3://${DEFAULT_S3_BUCKET}/dogImages/train/\\n!aws s3 sync ./dogImages/test s3://${DEFAULT_S3_BUCKET}/dogImages/test/\\n!aws s3 sync ./dogImages/valid s3://${DEFAULT_S3_BUCKET}/dogImages/valid/\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"DEFAULT_S3_BUCKET\"] = bucket\n",
    "!aws s3 sync ./dogImages/train s3://${DEFAULT_S3_BUCKET}/dogImages/train/\n",
    "!aws s3 sync ./dogImages/test s3://${DEFAULT_S3_BUCKET}/dogImages/test/\n",
    "!aws s3 sync ./dogImages/valid s3://${DEFAULT_S3_BUCKET}/dogImages/valid/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning\n",
    "**TODO:** This is the part where you will finetune a pretrained model with hyperparameter tuning. Remember that you have to tune a minimum of two hyperparameters. However you are encouraged to tune more. You are also encouraged to explain why you chose to tune those particular hyperparameters and the ranges.\n",
    "\n",
    "**Note:** You will need to use the `hpo.py` script to perform hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport sagemaker\\nfrom sagemaker.session import Session\\nfrom sagemaker import get_execution_role\\n\\nsession = sagemaker.Session()\\n\\nbucket= session.default_bucket()\\nprint(\"Default Bucket: {}\".format(bucket))\\n\\n#region = session.boto_region_name\\n#print(\"AWS Region: {}\".format(region))\\n\\nrole = get_execution_role() #sagemaker iam role\\nprint(\"RoleArn: {}\".format(role))\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import sagemaker\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "session = sagemaker.Session()\n",
    "\n",
    "bucket= session.default_bucket()\n",
    "print(\"Default Bucket: {}\".format(bucket))\n",
    "\n",
    "#region = session.boto_region_name\n",
    "#print(\"AWS Region: {}\".format(region))\n",
    "\n",
    "role = get_execution_role() #sagemaker iam role\n",
    "print(\"RoleArn: {}\".format(role))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Declare your HP ranges, metrics etc.\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"lr\": ContinuousParameter(0.001, 0.01), \n",
    "    \"batch-size\": CategoricalParameter([32, 64]),\n",
    "    \"epochs\": IntegerParameter(2, 4)\n",
    "}\n",
    "\n",
    "objective_metric_name = \"Test Loss\"\n",
    "objective_type = \"Minimize\"\n",
    "metric_definitions = [{\"Name\": \"Test Loss\", \"Regex\": \"Testing Loss: ([0-9\\\\.]+)\"}]\n",
    "\n",
    "\n",
    "#hyperparameters = {\"data_dir\":}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Create estimators for your HPs\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"hpo.py\",\n",
    "    role=get_execution_role(),\n",
    "    py_version='py36',\n",
    "    framework_version=\"1.8\",\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m4.xlarge'#,\n",
    "    #hyperparameters=hyperparameters\n",
    ")# TODO: Your estimator here\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator,\n",
    "    objective_metric_name,\n",
    "    hyperparameter_ranges,\n",
    "    metric_definitions,\n",
    "    max_jobs=2,\n",
    "    max_parallel_jobs=1,\n",
    "    objective_type=objective_type,\n",
    "    early_stopping_type=\"Auto\"\n",
    ")# TODO: Your HP tuner here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more on [HyperparameterTuner](https://sagemaker.readthedocs.io/en/stable/api/training/tuner.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit your HP Tuner\n",
    "tuner.fit({'train': f's3://{bucket}/dogImages'\n",
    "           },wait=True)\n",
    "# TODO: Remember to include your data channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get the best estimators and the best HPs\n",
    "\n",
    "best_estimator = tuner.best_estimator()\n",
    "\n",
    "#Get the hyperparameters of the best trained model\n",
    "best_estimator.hyperparameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Profiling and Debugging\n",
    "TODO: Using the best hyperparameters, create and finetune a new model\n",
    "\n",
    "**Note:** You will need to use the `train_model.py` script to perform model profiling and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sagemaker.pytorch import PyTorch\n",
    "#from sagemaker import get_execution_role\n",
    "from sagemaker.debugger import (\n",
    "    Rule,\n",
    "    DebuggerHookConfig,\n",
    "    rule_configs,\n",
    ")\n",
    "from sagemaker.debugger import ProfilerConfig, FrameworkProfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Set up debugging and profiling rules and hooks\n",
    "rules = [\n",
    "    Rule.sagemaker(rule_configs.vanishing_gradient()),\n",
    "    Rule.sagemaker(rule_configs.overfit()),\n",
    "    Rule.sagemaker(rule_configs.overtraining()),\n",
    "    Rule.sagemaker(rule_configs.poor_weight_initialization()),\n",
    "]\n",
    "\n",
    "hook_config = DebuggerHookConfig(\n",
    "    hook_parameters={\"train.save_interval\": \"100\", \"eval.save_interval\": \"10\"}\n",
    ")\n",
    "\n",
    "\n",
    "profiler_config = ProfilerConfig(\n",
    "    system_monitor_interval_millis=500, framework_profile_params=FrameworkProfile(num_steps=10)\n",
    ")\n",
    "\n",
    "#\"num_gpu\":True\n",
    "\n",
    "hyperparameters = {\"epochs\": \"2\", \"batch-size\": \"64\", \"test-batch-size\": \"100\", \"lr\": \"0.001\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-18 17:27:04 Starting - Starting the training job...\n",
      "2022-10-18 17:27:28 Starting - Preparing the instances for trainingProfilerReport-1666114024: InProgress\n",
      ".........\n",
      "2022-10-18 17:28:50 Downloading - Downloading input data.................\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-10-18 17:31:47,334 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-10-18 17:31:47,338 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-10-18 17:31:47,354 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-10-18 17:31:47,362 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-10-18 17:31:47,943 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-10-18 17:31:47,969 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-10-18 17:31:47,995 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-10-18 17:31:48,013 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": \"64\",\n",
      "        \"epochs\": \"2\",\n",
      "        \"lr\": \"0.001\",\n",
      "        \"test-batch-size\": \"100\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-dog-breed-pytorch-2022-10-18-17-27-04-278\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-298735464366/sagemaker-dog-breed-pytorch-2022-10-18-17-27-04-278/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_model\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 2,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.large\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.large\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_model.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":\"64\",\"epochs\":\"2\",\"lr\":\"0.001\",\"test-batch-size\":\"100\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_model.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_model\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-298735464366/sagemaker-dog-breed-pytorch-2022-10-18-17-27-04-278/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":\"64\",\"epochs\":\"2\",\"lr\":\"0.001\",\"test-batch-size\":\"100\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-dog-breed-pytorch-2022-10-18-17-27-04-278\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-298735464366/sagemaker-dog-breed-pytorch-2022-10-18-17-27-04-278/source/sourcedir.tar.gz\",\"module_name\":\"train_model\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.large\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.large\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_model.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"64\",\"--epochs\",\"2\",\"--lr\",\"0.001\",\"--test-batch-size\",\"100\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=2\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_TEST-BATCH-SIZE=100\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.6 train_model.py --batch-size 64 --epochs 2 --lr 0.001 --test-batch-size 100\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:31:51.500 algo-1:26 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:31:52.129 algo-1:26 INFO profiler_config_parser.py:102] Using config at /opt/ml/input/config/profilerconfig.json.\u001b[0m\n",
      "\n",
      "2022-10-18 17:31:49 Training - Training image download completed. Training in progress.\u001b[34m[2022-10-18 17:31:56.183 algo-1:26 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:31:56.186 algo-1:26 INFO hook.py:201] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:31:56.188 algo-1:26 INFO hook.py:255] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:31:56.188 algo-1:26 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:31:56.228 algo-1:26 INFO hook.py:591] name:fc.0.weight count_params:272384\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:31:56.228 algo-1:26 INFO hook.py:591] name:fc.0.bias count_params:133\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:31:56.229 algo-1:26 INFO hook.py:593] Total Trainable Params: 272517\u001b[0m\n",
      "\u001b[34mGet train data loader\u001b[0m\n",
      "\u001b[34mGet validation data loader\u001b[0m\n",
      "\u001b[34mGet test data loader\u001b[0m\n",
      "\u001b[34mSTART TRAINING\u001b[0m\n",
      "\u001b[34mEpoch 0, Phase train\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:31:59.048 algo-1:26 INFO hook.py:425] Monitoring the collections: losses\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:31:59.053 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/prestepzero-*-start-1666114312130412.2_train-0-stepstart-1666114319049895.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:31:59.078 algo-1:26 INFO hook.py:488] Hook is writing from the hook with pid: 26\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:32:22.460 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-0-stepstart-1666114319071730.2_train-0-forwardpassend-1666114342459720.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:32:23.569 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-0-forwardpassend-1666114342463857.5_train-1-stepstart-1666114343569444.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:33:33.045 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-1-stepstart-1666114343576837.0_train-1-forwardpassend-1666114413044735.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:33:34.133 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-1-forwardpassend-1666114413048010.5_train-2-stepstart-1666114414132704.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:34:41.008 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-2-stepstart-1666114414137626.8_train-2-forwardpassend-1666114481008297.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:34:42.207 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-2-forwardpassend-1666114481010689.5_train-3-stepstart-1666114482206487.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:35:50.246 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-3-stepstart-1666114482211970.0_train-3-forwardpassend-1666114550245651.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:35:51.430 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-3-forwardpassend-1666114550249224.2_train-4-stepstart-1666114551430074.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:36:58.360 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-4-stepstart-1666114551434418.8_train-4-forwardpassend-1666114618360386.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:36:59.573 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-4-forwardpassend-1666114618363007.8_train-5-stepstart-1666114619573557.2/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:38:07.410 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-5-stepstart-1666114619577906.0_train-5-forwardpassend-1666114687409971.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:38:08.736 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-5-forwardpassend-1666114687412205.5_train-6-stepstart-1666114688736034.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:39:16.459 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-6-stepstart-1666114688740763.0_train-6-forwardpassend-1666114756459189.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:39:17.836 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-6-forwardpassend-1666114756461545.5_train-7-stepstart-1666114757835611.5/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:40:26.200 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-7-stepstart-1666114757840992.5_train-7-forwardpassend-1666114826200250.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:40:27.662 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-7-forwardpassend-1666114826202978.2_train-8-stepstart-1666114827661728.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:41:34.972 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-8-stepstart-1666114827667271.2_train-8-forwardpassend-1666114894972339.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:41:36.666 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-8-forwardpassend-1666114894974958.5_train-9-stepstart-1666114896666583.8/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:42:43.036 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-9-stepstart-1666114896671323.0_train-9-forwardpassend-1666114963035949.0/python_stats.\u001b[0m\n",
      "\u001b[34m[2022-10-18 17:42:45.118 algo-1:26 INFO python_profiler.py:182] Dumping cProfile stats to /opt/ml/output/profiler/framework/pytorch/cprofile/26-algo-1/train-9-forwardpassend-1666114963038769.2_train-10-stepstart-1666114965117391.0/python_stats.\u001b[0m\n",
      "\u001b[34mEpoch 0, Phase valid\u001b[0m\n",
      "\u001b[34mSTART TRAINING\u001b[0m\n",
      "\u001b[34mEpoch 1, Phase train\u001b[0m\n",
      "\u001b[34mEpoch 1, Phase valid\u001b[0m\n",
      "\u001b[34mTesting Accuracy: 58.61244019138756, Testing Loss: 2.1350432400498094\u001b[0m\n",
      "\u001b[34mTesting Accuracy: 58.61244019138756, Testing Loss: 2.1350432400498094\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34mSaving the model.\u001b[0m\n",
      "\u001b[34mDownloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\u001b[0m\n",
      "\u001b[34m#015  0%|          | 0.00/97.8M [00:00<?, ?B/s]#015  2%|▏         | 1.50M/97.8M [00:00<00:06, 15.7MB/s]#015  6%|▌         | 5.93M/97.8M [00:00<00:02, 33.7MB/s]#015 10%|█         | 10.1M/97.8M [00:00<00:02, 37.9MB/s]#015 14%|█▍        | 14.1M/97.8M [00:00<00:02, 39.2MB/s]#015 19%|█▉        | 18.5M/97.8M [00:00<00:01, 41.8MB/s]#015 24%|██▎       | 23.1M/97.8M [00:00<00:01, 44.0MB/s]#015 28%|██▊       | 27.6M/97.8M [00:00<00:01, 45.0MB/s]#015 33%|███▎      | 32.2M/97.8M [00:00<00:01, 45.7MB/s]#015 38%|███▊      | 36.9M/97.8M [00:00<00:01, 46.9MB/s]#015 43%|████▎     | 41.6M/97.8M [00:01<00:01, 47.6MB/s]#015 47%|████▋     | 46.1M/97.8M [00:01<00:01, 43.8MB/s]#015 51%|█████▏    | 50.3M/97.8M [00:01<00:01, 42.4MB/s]#015 56%|█████▌    | 54.4M/97.8M [00:01<00:01, 42.4MB/s]#015 60%|██████    | 59.0M/97.8M [00:01<00:00, 44.1MB/s]#015 65%|██████▌   | 63.6M/97.8M [00:01<00:00, 45.2MB/s]#015 70%|██████▉   | 68.4M/97.8M [00:01<00:00, 46.7MB/s]#015 75%|███████▍  | 73.1M/97.8M [00:01<00:00, 47.3MB/s]#015 80%|███████▉  | 77.8M/97.8M [00:01<00:00, 47.8MB/s]#015 84%|████████▍ | 82.5M/97.8M [00:01<00:00, 48.3MB/s]#015 89%|████████▉ | 87.1M/97.8M [00:02<00:00, 47.3MB/s]#015 94%|█████████▎| 91.6M/97.8M [00:02<00:00, 46.9MB/s]#015 99%|█████████▊| 96.3M/97.8M [00:02<00:00, 47.6MB/s]#015100%|██████████| 97.8M/97.8M [00:02<00:00, 44.6MB/s]\u001b[0m\n",
      "\u001b[34mINFO:__main__:Get train data loader\u001b[0m\n",
      "\u001b[34mINFO:__main__:Get validation data loader\u001b[0m\n",
      "\u001b[34mINFO:__main__:Get test data loader\u001b[0m\n",
      "\u001b[34mINFO:__main__:Testing Accuracy: 58.61244019138756, Testing Loss: 2.1350432400498094\u001b[0m\n",
      "\u001b[34mINFO:__main__:Saving the model.\u001b[0m\n",
      "\u001b[34mINFO:__main__:Saving the model.\u001b[0m\n",
      "\u001b[34m2022-10-18 18:01:47,104 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-10-18 18:01:57 Uploading - Uploading generated training model\n",
      "2022-10-18 18:02:30 Completed - Training job completed\n",
      "Training seconds: 2020\n",
      "Billable seconds: 2020\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create and fit an estimator\n",
    "\n",
    "estimator =PyTorch(\n",
    "    entry_point=\"train_model.py\",\n",
    "    base_job_name=\"sagemaker-dog-breed-pytorch\",\n",
    "    role=get_execution_role(),\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    hyperparameters = hyperparameters,\n",
    "    framework_version = \"1.8\",\n",
    "    py_version=\"py36\",\n",
    "    debugger_hook_config=hook_config,\n",
    "    profiler_config=profiler_config\n",
    ")   \n",
    "\n",
    "estimator.fit({'train': f's3://{bucket}/dogImages'\n",
    "           },wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Plot a debugging output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Is there some anomalous behaviour in your debugging output? If so, what is the error and how will you fix it?  \n",
    "**TODO**: If not, suppose there was an error. What would that error look like and how would you have fixed it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source on Debugger](https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-debugger/pytorch_model_debugging/pytorch_script_change_smdebug.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sagemaker.pytorch.estimator.PyTorch at 0x7f9c09804690>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Display the profiler output\n",
    "estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deploying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Deploy your model to an endpoint\n",
    "\n",
    "predictor=estimator.deploy() # TODO: Add your deployment configuration like instance type and number of instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Run an prediction on the endpoint\n",
    "\n",
    "image = # TODO: Your code to load and preprocess image to send to endpoint for prediction\n",
    "response = predictor.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Remember to shutdown/delete your endpoint once your work is done\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
